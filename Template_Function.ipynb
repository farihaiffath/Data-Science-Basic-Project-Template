{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d67cd-9630-4840-a4c4-2a4f6f70f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRUD(Create, Read, Update, Delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71903e06-7e8d-4968-a90c-d947c2c35698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278671c5-b26d-4619-ba34-a3310bf5f455",
   "metadata": {},
   "source": [
    "#Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998fa53-331f-4abc-80bb-1a3632da7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Configuration and Setup\n",
    "# ============================\n",
    "# Define global constants and configurations\n",
    "SEED = 42  # For reproducibility\n",
    "DATA_PATH = 'data/'  # Path to datasets\n",
    "OUTPUT_PATH = 'output/'  # Path to save models, plots, etc.\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Helper function for reproducibility\n",
    "def set_seed(seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89c6eb-3d8d-48db-b72d-6196d186bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# 2. Data Loading Functions\n",
    "# ============================\n",
    "\n",
    "def load_from_local(file_path, file_type=\"csv\"):\n",
    "    \"\"\"\n",
    "    Load data from a local file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if file_type == \"csv\":\n",
    "            return pd.read_csv(file_path)\n",
    "        elif file_type == \"excel\":\n",
    "            return pd.read_excel(file_path)\n",
    "        elif file_type == \"json\":\n",
    "            return pd.read_json(file_path)\n",
    "        elif file_type == \"txt\":\n",
    "            return pd.read_csv(file_path, delimiter=\"\\t\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading local file: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_from_colab(file_id, file_type=\"csv\"):\n",
    "    \"\"\"\n",
    "    Load data from Google Drive in Colab.\n",
    "    Args:\n",
    "        file_id (str): Google Drive file ID.\n",
    "        file_type (str): \"csv\" or \"excel\".\n",
    "    Returns:\n",
    "        pd.DataFrame: Data as a DataFrame.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "        if file_type == \"csv\":\n",
    "            return pd.read_csv(url)\n",
    "        elif file_type == \"excel\":\n",
    "            return pd.read_excel(url)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type for Colab.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file from Colab: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_from_web(url, file_type=\"csv\"):\n",
    "    \"\"\"\n",
    "    Load data from a URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        if file_type == \"csv\":\n",
    "            return pd.read_csv(StringIO(response.text))\n",
    "        elif file_type == \"json\":\n",
    "            return pd.read_json(StringIO(response.text))\n",
    "        elif file_type == \"txt\":\n",
    "            return pd.read_csv(StringIO(response.text), delimiter=\"\\t\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file from web: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff97df-c87a-4707-af4d-cee8624d0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3. Data Preprocessing\n",
    "# ============================\n",
    "\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Perform basic data preprocessing such as handling missing values and encoding.\n",
    "    \"\"\"\n",
    "    print(f\"Initial Data Shape: {df.shape}\")\n",
    "    # Drop rows/columns with too many missing values\n",
    "    df = df.dropna(thresh=int(0.8 * len(df)), axis=1)  # Drop columns with > 80% missing values\n",
    "    df = df.dropna()  # Drop rows with missing values\n",
    "    print(f\"Shape after handling missing values: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29945ede-9d34-4b81-8a08-755ca670aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4. Exploratory Data Analysis (EDA)\n",
    "# ============================\n",
    "\n",
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Conduct basic exploratory data analysis.\n",
    "    \"\"\"\n",
    "    print(\"Basic Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # Visualize distributions\n",
    "    for column in df.select_dtypes(include=\"number\").columns:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.histplot(df[column], kde=True)\n",
    "        plt.title(f\"Distribution of {column}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa58722d-e86b-4e76-b7d2-e857219b868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================\n",
    "# 5. Model Training\n",
    "# ============================\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a simple machine learning model (Random Forest).\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877de7b3-32d6-464e-8321-342009f0869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 6. Model Evaluation\n",
    "# ============================\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on test data.\n",
    "    \"\"\"\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ce51d-de90-4f9f-9313-24a25399e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Main Pipeline\n",
    "# ============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load the data\n",
    "    local_file = os.path.join(DATA_PATH, \"sample.csv\")  # Replace with your file path\n",
    "    data = load_from_local(local_file, file_type=\"csv\")\n",
    "    if data is None:\n",
    "        print(\"Data loading failed. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # Step 2: Preprocess the data\n",
    "    data = preprocess_data(data)\n",
    "\n",
    "    # Step 3: Perform EDA\n",
    "    perform_eda(data)\n",
    "\n",
    "    # Step 4: Split the data into training and testing sets\n",
    "    target_column = \"target\"  # Replace with your target column\n",
    "    features = data.drop(columns=[target_column])\n",
    "    target = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    # Step 5: Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Step 6: Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
